{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed forward neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_data = datasets.load_breast_cancer()\n",
    "\n",
    "X = bc_data.data\n",
    "y = bc_data.target.astype(\"float\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.33,\n",
    "                                                    random_state=42)\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPModel:\n",
    "    def __init__(self):\n",
    "        self.n_layers = None\n",
    "        self.weights = None\n",
    "        self.input_dim = None\n",
    "        self.n_hidden = None\n",
    "        self.is_built = False\n",
    "\n",
    "    @staticmethod\n",
    "    def relu(x):\n",
    "        return np.maximum(x, 0)\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid(x):\n",
    "        return 1. / (1 + np.exp(-x))\n",
    "\n",
    "    def sigmoid_backward(self, da, z):\n",
    "        sig = self.sigmoid(z)\n",
    "        return da * sig * (1 - sig)\n",
    "\n",
    "    @staticmethod\n",
    "    def relu_backward(da, z):\n",
    "        dz = np.array(da, copy=True)\n",
    "        dz[z <= 0] = 0\n",
    "        return dz\n",
    "\n",
    "    def build_model(self, input_dim, n_hidden, n_layers=2, activation=\"relu\"):\n",
    "        self.n_layers = n_layers\n",
    "        self.input_dim = input_dim\n",
    "        self.weights = []\n",
    "        self.activations = []\n",
    "        prev_d = input_dim\n",
    "        for l, d in enumerate(n_hidden):\n",
    "            w = np.random.normal(0, np.sqrt(2/prev_d), (d, prev_d))    # N(0, sqrt(2/inp_dim))\n",
    "            b = np.random.normal(0, np.sqrt(2/prev_d), (d, 1))\n",
    "\n",
    "            prev_d = d\n",
    "            self.weights.append((w, b))\n",
    "            if activation == \"relu\":\n",
    "                self.activations.append(self.relu)\n",
    "            elif activation == \"sigmoid\":\n",
    "                self.activations.append(self.sigmoid)\n",
    "            else:\n",
    "                raise(\"Unsupported activation\")\n",
    "\n",
    "        # Sigmoid output layer\n",
    "        w = np.random.normal(0, np.sqrt(2/prev_d), (1, prev_d))    # N(0, sqrt(2/inp_dim))\n",
    "        b = np.random.normal(0, np.sqrt(2/prev_d), (1, 1))\n",
    "        self.weights.append((w, b))\n",
    "        self.activations.append(self.sigmoid)\n",
    "\n",
    "        self.is_built = True\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_i = x.T\n",
    "        # the initial input is the first in mem\n",
    "        z = [h_i]\n",
    "        h = [h_i]\n",
    "        for i, ((w, b), activation_fn) in enumerate(zip(self.weights, self.activations)):\n",
    "            z_i = np.dot(w, h_i) + b\n",
    "            z.append(z_i)\n",
    "            h_i = activation_fn(z_i)\n",
    "            h.append(h_i)\n",
    "\n",
    "        return np.squeeze(h_i), (z, h)\n",
    "\n",
    "    def backward(self, h, y, mem):\n",
    "        da = - (np.divide(y, h) - np.divide(1 - y, 1 - h))\n",
    "        grads = []\n",
    "        for i in range(self.n_layers, -1, -1):\n",
    "            w, b = self.weights[i]\n",
    "            activation_fn = self.activations[i]\n",
    "            # mem also has the first layer so it is i + 1\n",
    "            z_cur, h_cur = mem[0][i+1], mem[1][i+1]\n",
    "            z_prev, h_prev = mem[0][i], mem[1][i]\n",
    "            m = h_prev.shape[1]\n",
    "\n",
    "            if activation_fn.__name__ == \"relu\":\n",
    "                dz = self.relu_backward(da, z_cur)\n",
    "            elif activation_fn.__name__ == \"sigmoid\":\n",
    "                dz = self.sigmoid_backward(da, z_cur)\n",
    "            else:\n",
    "                raise(\"Unsupported activation\")\n",
    "            \n",
    "            dw = np.dot(dz, h_prev.T) / m\n",
    "            db = np.sum(dz, axis=1, keepdims=True) / m\n",
    "            da = np.dot(w.T, dz)\n",
    "\n",
    "            grads.append((dw, db))\n",
    "        \n",
    "        return grads\n",
    "\n",
    "    def update_weights(self, grads, lr):\n",
    "        grads = list(reversed(grads))    # grads have the opposite order\n",
    "        for i, (w, b) in enumerate(self.weights):\n",
    "            grad_w, grad_b = grads[i]\n",
    "            w -= lr*grad_w\n",
    "            b -= lr*grad_b\n",
    "            self.weights[i] = (w, b)\n",
    "\n",
    "    def crossentropy_loss(self, h, y, eps=1e-8):\n",
    "        m = h.shape[0]\n",
    "        # without eps log(0) will eval to nan\n",
    "        j = -(1.0 / m) * (np.dot(y, np.log(h + eps).T) + np.dot(1.0 - y, np.log(1.0 - h + eps).T))\n",
    "        return np.squeeze(j)\n",
    "\n",
    "    def get_cost_value(self, Y_hat, Y, eps=1e-8):\n",
    "        m = Y_hat.shape[0]\n",
    "        cost = -1 / m * (np.dot(Y, np.log(Y_hat + eps).T) + np.dot(1 - Y, np.log(1 - Y_hat + eps).T))\n",
    "        return np.squeeze(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier:\n",
    "    def __init__(self, n_hidden, n_layers=2, lr=0.003, activation=\"relu\"):\n",
    "        assert len(n_hidden) == n_layers\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_layers = n_layers\n",
    "        self.lr = lr\n",
    "        self.activation = activation\n",
    "        self.model = MLPModel()\n",
    "\n",
    "    def make_datagen(self, X, y=None, batch_size=16):\n",
    "        for i in range(0, len(X), batch_size):\n",
    "            x_batch = X[i:i+batch_size]\n",
    "            if y is not None:    # for training\n",
    "                y_batch = y[i:i+batch_size]\n",
    "                assert x_batch.shape[0] == y_batch.shape[0]\n",
    "                yield x_batch, y_batch\n",
    "            else:    # for prediction\n",
    "                yield x_batch\n",
    "\n",
    "    def shuffle_data(self, X, y):\n",
    "        x_temp = np.concatenate([X, np.expand_dims(y, axis=1)], axis=1)\n",
    "        np.random.shuffle(x_temp)\n",
    "        X, y = x_temp[:, :-1], np.squeeze(x_temp[:, -1])\n",
    "        return X, y\n",
    "\n",
    "    def fit(self, X_train, y_train, epochs=100, batch_size=16, shuffle=True):\n",
    "        self.model.build_model(\n",
    "                input_dim=X_train.shape[1],\n",
    "                n_layers=self.n_layers,\n",
    "                n_hidden=self.n_hidden,\n",
    "                activation=self.activation)\n",
    "        \n",
    "        epoch = 0\n",
    "        losses = []\n",
    "        avg_loss = float(\"inf\")\n",
    "        while epoch < epochs:\n",
    "            datagen = self.make_datagen(X_train, y_train, batch_size)\n",
    "            epoch_loss = 0\n",
    "            for i, (x, y) in enumerate(datagen):\n",
    "                h, mem = self.model.forward(x)\n",
    "                loss = self.model.crossentropy_loss(h, y)\n",
    "                epoch_loss += loss\n",
    "\n",
    "                grads = self.model.backward(h, y, mem)\n",
    "\n",
    "                self.model.update_weights(grads, self.lr)\n",
    "\n",
    "            avg_loss = epoch_loss / (i+1)\n",
    "            losses.append(avg_loss)\n",
    "\n",
    "            if shuffle:\n",
    "                X_train, y_train = self.shuffle_data(X_train, y_train)\n",
    "            \n",
    "            epoch += 1\n",
    "        \n",
    "        return losses\n",
    "\n",
    "    def predict(self, X_test, batch_size=16):\n",
    "        assert self.model.is_built    # will fail if fit hasn't been called\n",
    "        datagen = self.make_datagen(X_test, batch_size=batch_size)\n",
    "        y_ret = []\n",
    "        for i, x in enumerate(datagen):\n",
    "            y_pred, _ = self.model.forward(x)\n",
    "            # threshold at 0.5\n",
    "            y_pred[y_pred >= 0.5] = 1\n",
    "            y_pred[y_pred < 0.5] = 0\n",
    "            y_ret.append(y_pred)\n",
    "\n",
    "        return np.concatenate(y_ret, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7efc4513fad0>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlp_clf = MLPClassifier(n_hidden=[50, 20], lr=0.003, activation=\"relu\")\n",
    "losses = mlp_clf.fit(X_train, y_train, epochs=100, batch_size=32)\n",
    "plt.plot(range(len(losses)), losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_r = mlp_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9521276595744681"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_r, average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
